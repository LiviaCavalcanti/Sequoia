from typing import Callable, List, Optional, Tuple

import gym
import pytest

from common.transforms import ChannelsFirstIfNeeded, ToTensor, Transforms
from conftest import xfail_param
from utils.utils import take

from .continual_rl_setting import ContinualRLSetting


# @pytest.mark.xfail(reason="BUG: See the docstring below. For now don't depend on the shape of the `reset` return value.")
@pytest.mark.parametrize("batch_size", [1, 2, 10])
@pytest.mark.parametrize(
    "dataset,transforms,expected_obs_shape",
    [
        # Use the default transforms (atm: [to_tensor, channels_first_if_needed))
        xfail_param("cartpole", None, (3, 400, 600), reason="BUG: See docstring below"),
        # Using no transforms.
        ("cartpole", [], (400, 600, 3)),
        xfail_param("cartpole", [Transforms.channels_first], (3, 400, 600), reason="BUG: See docstring below"),
    ],
)
def test_step_and_reset_give_same_shape_obs(dataset: str,
                                            transforms: Optional[List[Callable]],
                                            expected_obs_shape: Tuple[int, ...],
                                            batch_size: int):
    """ Test that the return value of 'step' and 'reset' have the same shape,
    even when using transforms.
    
    
    There is this very weird bug happening, where the transforms are used
    when stepping, but not when resetting..

    We've been using `TransformObservations` wrapper from gym, which is supposed
    to actually apply the transformation to reset as well.. idk what's happening
    here.
    """
    if transforms is None:
        # Use the default transforms.
        setting = ContinualRLSetting(dataset=dataset)
    else:
        setting = ContinualRLSetting(dataset=dataset, transforms=transforms)
    # Check that the `obs_shape` property is what you'd expect.
    assert setting.obs_shape == expected_obs_shape
    
    expected_obs_batch_shape = (batch_size, *expected_obs_shape)

    # Test the shapes of the obs generated by the train/val/test dataloaders.
    dataloader_methods = [
        setting.train_dataloader,
        setting.val_dataloader,
        setting.test_dataloader
    ]
    for dataloader_method in dataloader_methods:
        dataloader = dataloader_method(batch_size=batch_size)
        # HERE: seems like the transforms aren't used on reset!
        reset_obs = dataloader.reset()
        assert reset_obs.shape == expected_obs_batch_shape
        
        step_obs, *_ = dataloader.step(dataloader.random_actions())
        assert step_obs.shape == expected_obs_batch_shape
        
        for iter_obs, *_ in take(dataloader, 3):
            assert iter_obs.shape == expected_obs_batch_shape
            reward = dataloader.send(dataloader.random_actions())


@pytest.mark.parametrize("batch_size", [1, 3])
@pytest.mark.parametrize(
    "dataset, expected_obs_shape", [
        ("cartpole",  (4,)),
    ],
)
def test_observe_state_directly(dataset: str,
                                expected_obs_shape: Tuple[int, ...],
                                batch_size: int):
    setting = ContinualRLSetting(dataset=dataset, observe_state_directly=True)
    assert setting.obs_shape == expected_obs_shape
    
    expected_obs_batch_shape = (batch_size, *expected_obs_shape)

    # Test the shapes of the obs generated by the train/val/test dataloaders.
    dataloader_methods = [
        setting.train_dataloader,
        setting.val_dataloader,
        setting.test_dataloader
    ]
    for dataloader_method in dataloader_methods:
        dataloader = dataloader_method(batch_size=batch_size)
        reset_obs = dataloader.reset()
        assert reset_obs.shape == expected_obs_batch_shape
        step_obs, *_ = dataloader.step(dataloader.random_actions())
        assert step_obs.shape == expected_obs_batch_shape
        for iter_obs, *_ in take(dataloader, 3):
            assert iter_obs.shape == expected_obs_batch_shape 
            reward = dataloader.send(dataloader.random_actions())


@pytest.mark.xfail(reason=f"TODO: DQN model only accepts string environment names...")
def test_dqn_on_env():
    """ TODO: Would be nice if we could have the models work directly on the
    gym envs..
    """
    from pl_bolts.models.rl import DQN
    from pytorch_lightning import Trainer
    setting = ContinualRLSetting(observe_state_directly=False)
    env = setting.train_dataloader(batch_size=5)
    model = DQN("PongNoFrameskip-v4")
    trainer = Trainer(fast_dev_run=True)
    trainer.fit(model)
    assert False
